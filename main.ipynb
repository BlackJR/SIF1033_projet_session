{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# 1) Développer une interface qui permet d’introduire vos données (images ou vidéo)\n",
    "# Assurez-vous d'avoir un dossier \"data\" avec les sous-dossiers pour chaque classe d'image (par exemple : explosif, inflammable, toxique, etc.)\n",
    "data_dir = 'data'\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "# Créez des générateurs d'images pour l'entraînement et la validation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# 2) Extraire les objets à classifier/interpréter/reconnaître à partir des données originales.\n",
    "# 3) Caractériser chaque objet en utilisant des mesures descriptives appropriées.\n",
    "# 4) Implémenter et tester l’algorithme de classification de formes.\n",
    "# Construire le modèle\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Entraîner le modèle\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Enregistrer le modèle entraîné\n",
    "model.save('pictogrammes_dangereux.h5')\n",
    "\n",
    "# Afficher les courbes d'apprentissage\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs), history.history['loss'], label='Perte (entraînement)')\n",
    "plt.plot(range(epochs), history.history['val_loss'], label='Perte (validation)')\n",
    "plt.xlabel('Ésure') # Ajoute l'étiquette 'Époque' à l'axe des x\n",
    "plt.ylabel('Perte') # Ajoute l'étiquette 'Perte' à l'axe des y\n",
    "plt.legend() # Ajoute la légende\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs), history.history['accuracy'], label='Précision (entraînement)')\n",
    "plt.plot(range(epochs), history.history['val_accuracy'], label='Précision (validation)')\n",
    "plt.xlabel('Époque') # Ajoute l'étiquette 'Époque' à l'axe des x\n",
    "plt.ylabel('Précision') # Ajoute l'étiquette 'Précision' à l'axe des y\n",
    "plt.legend() # Ajoute la légende\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
